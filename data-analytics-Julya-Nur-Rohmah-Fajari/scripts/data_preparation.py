# -*- coding: utf-8 -*-
"""data preparation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gBOBzv0Kp8KNv_Xbz_M4MQFjAOqXHS2S
"""

#import library
import pandas as pd
import ast
import numpy as np
import os

"""#Import File"""

#import file dari github
url = "https://raw.githubusercontent.com/cinte-id/book-app/main/backend/books.json"
df = pd.read_json(url)

#tampilkan file
pd.set_option('display.max_columns', None)
print(df.head())

#ubah ke file csv
df.to_csv('books_raw.csv', index=False)

df_csv = pd.read_csv('books_raw.csv')

#ubah string JSON di kolom 'books' jadi dictionary Python
df_csv['books'] = df_csv['books'].apply(ast.literal_eval)

#pecah kolom 'books' jadi kolom terpisah (normalize)
df_clean = pd.json_normalize(df_csv['books'])

#tampilkan hasilnya
df_clean.head()

"""#Cleaning"""

#pengecekan format data
df_clean.info()

"""Tidak ada data kosong jadi lanjut pada tahap pengecekan duplikat"""

#mengecek apakah ada duplikat
duplicates = df_clean.duplicated()
print(duplicates.value_counts())  # Berapa True/False

#menampilkan baris yang duplikat
print(df_clean[duplicates])

"""Tidak terdapat duplikat pada data ini dan dapat dilanjutkan pada tahap create sample user interaction data

#Create Sample User Interaction Data
"""

#buat daftar sample 20 user fiktif
user_ids = [f'U{i:03d}' for i in range(1, 21)]

#buat data interaksi 100
n_records = 100
df_interactions = pd.DataFrame({
    'user_id': np.random.choice(user_ids, n_records),
    'book_id': np.random.choice(df_clean['id'], n_records),
    'event_type': np.random.choice(['view', 'search', 'rating'], n_records, p=[0.4, 0.4, 0.2]),
    'rating': np.random.randint(1, 6, n_records)  # 1–5
})

#hapus rating untuk event selain 'rating'
df_interactions.loc[df_interactions['event_type'] != 'rating', 'rating'] = np.nan

#tambahkan timestamp acak (Januari–Oktober 2025)
df_interactions['timestamp'] = pd.to_datetime(
    np.random.choice(pd.date_range('2025-01-01', '2025-10-22', freq='h'), n_records)
)

#tampilkan data
df_interactions.head()

#cek info df_intercation
df_interactions.info()

#cek persebaran event_type
df_interactions['event_type'].value_counts(normalize=True).round(2)

"""diketahui bahwa persebaran event type rating sebanyak 20 sehingga data rating hanya 20"""

#cek nilai rating hanya muncul di event_type='rating'
invalid_ratings = df_interactions[(df_interactions['event_type'] != 'rating') & (df_interactions['rating'].notna())]
print(f"Jumlah rating tidak valid: {len(invalid_ratings)} (harusnya 0)\n")

#cek duplikasi
duplicates = df_interactions.duplicated(subset=['user_id', 'book_id', 'event_type']).sum()
print(f"Jumlah duplikasi user+book+event: {duplicates}\n")

#cek baris duplikasi
df_interactions[df_interactions.duplicated(subset=['user_id', 'book_id', 'event_type'], keep=False)].sort_values(['user_id', 'book_id'])

#cek variasi user dan buku
print(f"Total unique user: {df_interactions['user_id'].nunique()}")
print(f"Total unique book: {df_interactions['book_id'].nunique()}")
print(f"Rentang tanggal interaksi: {df_interactions['timestamp'].min()} - {df_interactions['timestamp'].max()}")

"""Duplikasi pada data ini tidak perlu dihapus karena data tidak menghasiolkan redundant dan dapat digunakan untuk menganalisis pola perilaku user dan nilai uniq pada data ini tetap 20 user dan 8 buku."""